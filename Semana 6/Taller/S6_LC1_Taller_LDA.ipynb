{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso-taller:  Recomendando el Blog de  Hernán Casciari \n",
    "\n",
    "\n",
    "[Hernán Casciari](https://hernancasciari.com/#bio), es un escritor argentino, que escribe blog posts con cuentos e historias  relacionadas con el futbol, su vida, infancia, y relaciones familiares con toques de ficción. Este [blog](https://hernancasciari.com/blog/) es  tan interesantes que en 2005 fue premiado como “El mejor blog del mundo” por Deutsche Welle de Alemania. \n",
    "\n",
    "El objetivo de este caso-taller es construir un sistema de recomendación basado en los contenidos de los posts utilizando similitud de las palabras usadas o temas de los cuentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales\n",
    "\n",
    "1. Para desarrollar el *cuaderno*, primero debe descargarlo.\n",
    "\n",
    "2. Para responder cada inciso deberá utilizar el espacio debidamente especificado.\n",
    "\n",
    "3. La actividad será calificada sólo si sube el *cuaderno* de jupyter notebook con extensión `.ipynb` en la actividad designada como \"entrega calificada por el personal\".\n",
    "\n",
    "4. El archivo entregado debe poder ser ejecutado localmente por el tutor. Sea cuidadoso con la especificación de la ubicación de los archivos de soporte, guarde la carpeta de datos en el mismo `path` de su cuaderno, por ejemplo: `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga de datos \n",
    "\n",
    "En la carpeta `data` se encuentran el archivo `blog_casciari.csv` con el título, la fecha de publicación, y el contenido de los cuentos publicados en el blog  de sr. Casciari. Cargue estos datos en su *cuaderno* y reporte brevemente el contenido de la base.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\YOLANDA\\AppData\\Local\\Microsoft\\WindowsApps\\python3.7.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/YOLANDA/AppData/Local/Microsoft/WindowsApps/python3.7.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('blog_casciari.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa8eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\YOLANDA\\AppData\\Local\\Microsoft\\WindowsApps\\python3.7.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/YOLANDA/AppData/Local/Microsoft/WindowsApps/python3.7.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f67b36",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\YOLANDA\\AppData\\Local\\Microsoft\\WindowsApps\\python3.7.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/YOLANDA/AppData/Local/Microsoft/WindowsApps/python3.7.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa46618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['fecha'] = pd.to_datetime(df['fecha'], format='%m/%d/%y')\n",
    "df['año'] = df['fecha'].dt.year\n",
    "conteo_por_año = df['año'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(conteo_por_año.index, conteo_por_año.values)\n",
    "plt.xlabel('Número de observaciones')\n",
    "plt.ylabel('Año')\n",
    "plt.title('Número de observaciones por año (Gráfico Horizontal)')\n",
    "\n",
    "plt.yticks(conteo_por_año.index)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar, se almacenan los datos del blog en un data frame de pandas llamado df a través de la función read_csv. A continuación se verifican las dimensiones del data frame, de donde se obtienen 520 filas y 3 columnas. Es decir que el blog contiene 520 cuentos. A través de head se ven las primeras observaciones y con info se verifica que no hay valores nulos en la base de datos. También se hace un gráfico para verificar el año de escritura de los cuentos. Acá se concluye que el año en el que más cuentos se escribieron en el blog fue en 2004."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Homogenización de textos\n",
    "\n",
    "Para cumplir con el objetivo de generar recomendaciones en esta sección debe preparar los posts para poder ser utilizados en su sistema de recomendación. Para ello, \"limpie\" y \"tokenize\" cada uno de los cuentos, describiendo detalladamente los pasos que realizo y si transformó o eliminó ciertas palabras. Para asistirlo en la tarea he creado listas de *stopwords* que están disponibles en la carpeta `data`. En su procedimiento ilustre la limpieza con el cuento 'La venganza del metegol'. (En su limpieza recuerde que el objetivo es generar recomendaciones a partir de la similitud de las palabras o temas de los cuentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb1fdf",
   "metadata": {},
   "source": [
    "Para comenzar, se mostrará el paso a paso con el cuento \"La venganza del metegol\" y a continuación se realizará todo el procedimiento a partir de una sola función para todos los cuentos. En primer lugar, se verifica la posición en la que se encuentra este cuento. De este modo, se verifica que se encuentra en la fila 160."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['titulo'] == \"La venganza del metegol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta información, se genera un objeto llamado metegol que contiene el cuento solicitado y se muestra su texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a19d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = df['cuento'][160]\n",
    "metegol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89387b21",
   "metadata": {},
   "source": [
    "Se importan las librerías re para el tratamiento de las expresiones regulares y unidecode para eliminar caracteres no deseados transformando el texto en ASCII a través de la función unidecode. A continuación se muestran los primeros 1000 caracteres del texto, donde se verifica que se eliminaron tildes y virgulillas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "\n",
    "metegol = unidecode.unidecode(metegol)\n",
    "metegol[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a85eb8",
   "metadata": {},
   "source": [
    "Con la función sub se trabajan las expresiones regulares. ^\\w\\s es una clase de caracteres negada que busca cualquier carácter que no sea una letra o un dígito (\\w) ni un espacio en blanco (\\s). En otras palabras, busca cualquier carácter que no sea una letra, un dígito o un espacio en blanco. El símbolo | actúa como un operador OR, lo que significa que estamos buscando cualquier carácter que coincida con el patrón anterior (cualquier carácter que no sea una letra, un dígito o un espacio en blanco) o el siguiente patrón. \\n representa el carácter de nueva línea en una cadena de texto. Todos estos patrones se reemplazan por espacios en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = re.sub(\"[^\\\\w\\\\s]|\\n\", ' ', metegol)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6ccdb",
   "metadata": {},
   "source": [
    "En el código que se muestra a continuación se eliminan los dígitos del texto por espacios en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = re.sub(\"\\d+\", \"\", metegol)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6bcaba",
   "metadata": {},
   "source": [
    "A continuación, se eliminan los espacios extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8724b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = re.sub('\\s+', ' ', metegol)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39f22d",
   "metadata": {},
   "source": [
    "Y se pasa todo el texto a minúsculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol =  metegol.lower()\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce8425",
   "metadata": {},
   "source": [
    "A continuación se importa spacy, que es una librería que será usada para la lematización y la tokenización. La línea de código nlp = spacy.load(\"es_core_news_sm\") se utiliza para cargar un modelo de procesamiento de lenguaje natural (NLP) pre-entrenado para el español. El modelo es guardado en el objeto nlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20414fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c21101",
   "metadata": {},
   "source": [
    "Este modelo pre entrenado es aplicado al cuento elegido previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = nlp(metegol)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb548b",
   "metadata": {},
   "source": [
    "Para eliminar los stopwords se usan los suministrados por el equipo docente para este ejercicio, añadiéndolas a las stopwords predefinidas en el modelo cargado previamente. Estas están contenidas en extra_stopwords y stopwords_taller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords = pd.read_csv('extra_stopwords.csv', sep=',',header=None)\n",
    "extra_stopwords.columns = ['stopwords']\n",
    "extra_stopwords=set(extra_stopwords['stopwords'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_taller = pd.read_csv('stopwords_taller.csv', sep=',',header=None)\n",
    "stopwords_taller.columns = ['stopwords']\n",
    "stopwords_taller=set(stopwords_taller['stopwords'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f900e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words |= extra_stopwords\n",
    "nlp.Defaults.stop_words |= stopwords_taller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3d86e",
   "metadata": {},
   "source": [
    "Así, se conservan solamente las palabras que no están en la lista de stopwords. De aquí se evidencia que se elimina la palabra \"Buenos\" que quizás convendría conservar debido a que en la literatura hispanoamericana es muy habitual que en la narrativa, el espacio geográfico sea protagónico, por lo cual las ciudades podrían incluirse en los sistemas de recomendación y la eliminación de esta palabra excluye \"Buenos Aires\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef541d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = [token.text for token in metegol if not token.is_stop]\n",
    "metegol = \" \".join(metegol)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600816c",
   "metadata": {},
   "source": [
    "A continuación, se realiza la lematización. En esta, se observa que hay algunas palabras que no se lematizan correctamente. Por ejemplo, charla se convierte en char él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1960f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas =[token.lemma_ for token in nlp(metegol)]\n",
    "\n",
    "metegol = \" \".join(lemmas)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3041175",
   "metadata": {},
   "source": [
    "Debido a que muchas veces se ha observado que, en la lematización se genera el término \"él\", se elimina este del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d38016",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = re.sub('él', '', metegol)\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0aa40",
   "metadata": {},
   "source": [
    "Se genera entonces una lista de palabras, pero solamente aquellas palabras con más de 2 caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metegol = [token.text for token in nlp(metegol) if len(token) > 2]\n",
    "print(metegol[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a49ca",
   "metadata": {},
   "source": [
    "Todos estos procedimientos se resumen en una función, dejando la aclaración que esta función asume que previamente se han agregado las stop_words suministradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra_stopwords = pd.read_csv('extra_stopwords.csv', sep=',',header=None)\n",
    "#extra_stopwords.columns = ['stopwords']\n",
    "#extra_stopwords=set(extra_stopwords['stopwords'].to_list())\n",
    "#stopwords_taller = pd.read_csv('stopwords_taller.csv', sep=',',header=None)\n",
    "#stopwords_taller.columns = ['stopwords']\n",
    "#stopwords_taller=set(stopwords_taller['stopwords'].to_list())\n",
    "#nlp.Defaults.stop_words |= extra_stopwords\n",
    "#nlp.Defaults.stop_words |= stopwords_taller\n",
    "def text_cleaning(txt):\n",
    "    \n",
    "    # Eliminar caracteres especiales\n",
    "    out = unidecode.unidecode(txt)\n",
    "    out = re.sub(\"[^\\\\w\\\\s]|\\n\", ' ', out)\n",
    "    out = re.sub(\"\\d+\", \"\", out)\n",
    "    out = re.sub('\\s+', ' ', out)\n",
    "    # Poner en minúsculas\n",
    "    out = out.lower()\n",
    "    #NLP object\n",
    "    out = nlp(out)\n",
    "    # Eliminar Stopwords\n",
    "    out = [token.text for token in out if not token.is_stop]\n",
    "    out = \" \".join(out)\n",
    "    # Obtener los lemas de cada palabra\n",
    "    lemmas =[token.lemma_ for token in nlp(out)]\n",
    "    # Convertir la lista de lemmas nuevamente a texto\n",
    "    out = \" \".join(lemmas)\n",
    "    # Remover \"él\"\n",
    "    out = re.sub('él', '', out)\n",
    "    # Remover palabras muy cortas\n",
    "    out = [token.text for token in nlp(out) if len(token) > 2]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39def316",
   "metadata": {},
   "source": [
    "La limpieza definida en esta función es aplicada a cada uno de los cuentos, que son almacenados ya limpios en una lista. Con esta se unen los tokens en un objeto llamado clean_sentences en donde cada línea es un cuento. La línea 160 muestra el cuento \"La venganza del metegol\" con todo el proceso de limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = list(map(text_cleaning, df['cuento']))\n",
    "\n",
    "clean_sentences = [\" \".join(i) for i in clean]\n",
    "\n",
    "# Vemos la linea 100 limpia\n",
    "print(clean_sentences[160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generando Recomendaciones\n",
    "\n",
    "En esta sección nos interesa generar recomendaciones de cuentos en el blog a un usuario que leyó 'La venganza del metegol'. Para ello vamos a utilizar distintas estrategias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Recomendaciones basadas en contenidos\n",
    "\n",
    "##### 3.1.1. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando en la distancia de coseno donde el texto este vectorizado por `CountVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cb309",
   "metadata": {},
   "source": [
    "Se importa CountVectorizer de sklearn y el modelo es guardado en un objeto llamado count. Este es aplicado a clean_sentences, de donde se genera una matriz con 520 filas y 24622 columnas (términos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(clean_sentences)\n",
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612f84f",
   "metadata": {},
   "source": [
    "Esta matriz se convierte a un formato denso almacenado en un data frame denominado df_count que contiene el mismo número de filas y columnas que la matriz anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eede632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.DataFrame(count_matrix.toarray(), columns=count.get_feature_names_out())\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esta función se identifican algunos términos que no fueron lematizados correctamente, por lo cual se crea la función Lematizador_propio para abandonar, abalanzar, zurdo, zurrar y zozobrar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25993581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lematizador_propio(text):\n",
    "    # Diccionario con las palabras y sus lemas correspondientes\n",
    "    lemmas = {\n",
    "        r\"\\babandona\\b\": \"abandonar\",\n",
    "        r\"\\babandonado\\b\": \"abandonar\",\n",
    "        r\"\\babandonandolo\\b\": \"abandonar\",\n",
    "        r\"\\babandonar\\b\": \"abandonar\",\n",
    "        r\"\\babandono\\b\": \"abandonar\",\n",
    "        r\"\\babandón\\b\": \"abandonar\",\n",
    "        r\"\\babalanzo\\b\": \"abalanzar\",\n",
    "        r\"\\bzurda\\b\": \"zurdo\",\n",
    "        r\"\\bzurdazo\\b\": \"zurdo\",\n",
    "        r\"\\bzurdito\\b\": \"zurdo\",\n",
    "        r\"\\bzurraba\\b\": \"zurrar\",\n",
    "        r\"\\bzurrartir\\b\": \"zurrar\",\n",
    "        r\"\\bzozobra\\b\": \"zozobrar\"\n",
    "    }\n",
    "    for pattern, lemma in lemmas.items():\n",
    "        text = re.sub(pattern, lemma, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "clean_sentences2 = list(map(Lematizador_propio, clean_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b98da",
   "metadata": {},
   "source": [
    "Después de aplizar el nuevo lematizador, se aplica de nuevo el conteo de términos con CountVectorizer, disminuyendo el número de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47437d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(clean_sentences2)\n",
    "\n",
    "df_count = pd.DataFrame(count_matrix.toarray(), columns=count.get_feature_names_out())\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133c398",
   "metadata": {},
   "source": [
    "Se importa linear_kernel con el fin de calcular la distancia de coseno en la matriz count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b402ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cosine_sim = linear_kernel(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0fe7c",
   "metadata": {},
   "source": [
    "Ahora, se define la función de recomendador donde se extraen los índices, se identifica el índice del cuento requerido por la función en la opción titulo y se extraen los puntajes de similitud de coseno aplicados a este cuento. En el paso 6 se extraen los primeros 5 cuentos con mayor puntaje en la similitud de coseno que fueron ordenados en el paso 5. No se incluye el elemento 0 de la lista debido a que este corresponde al mismo cuento solicitado en la función.La función retorna los títulos de los cuentos similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1989409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendador(titulo, cosine_sim=cosine_sim, df=df):\n",
    "    #Paso 2\n",
    "    df = df.reset_index()\n",
    "    indices = pd.Series(df.index, index=df['titulo']).drop_duplicates()\n",
    "    #Paso 3\n",
    "    idx = indices[titulo]\n",
    "\n",
    "    #Paso 4\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #Paso 5\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #Paso 6\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    cuento_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #Paso 7\n",
    "    return df['titulo'].iloc[cuento_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39de6f4",
   "metadata": {},
   "source": [
    "Se prueba la función y se obtienen los 5 cuentos recomendados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendador(\"La venganza del metegol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b2ca6",
   "metadata": {},
   "source": [
    "A través de una nube de palabras se obtienen los términos más usados en estos cuentos. De aquí se ve que los términos están relacionados con la visión y la fotografía. Aun así, hay algunas palabras muy repetidas que quizás no son tan informativos como por ejemplo año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cuentos_rec=df[df['titulo'].isin(recomendador(\"La venganza del metegol\"))]\n",
    "\n",
    "text = \" \".join(cuentos_rec['cuento'])\n",
    "text = text_cleaning(text)\n",
    "text=' '.join(text)\n",
    "text = Lematizador_propio(text)\n",
    "\n",
    "wordcloud = WordCloud(width = 1600, height = 800, \n",
    "    background_color = \"white\").generate(text)\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para  el cuento 'La venganza del metegol' usando nuevamente la distancia de coseno, pero ahora vectorice el texto usando `TF-IDFVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados del punto anterior y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42842eb",
   "metadata": {},
   "source": [
    "Se importa TfidfVectorizer de sklearn y el modelo es guardado en un objeto llamado tfidf. Este es aplicado a clean_sentences, de donde se genera una matriz con 520 filas y 24622 columnas (términos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(clean_sentences)\n",
    "tfidf_matrix.shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378bff8",
   "metadata": {},
   "source": [
    "Esta matriz se convierte a un formato denso almacenado en un data frame denominado df_count que contiene el mismo número de filas y columnas que la matriz anterior. La diferencia con el método CountVectorizer es que en este caso no se generan conteos sino puntajes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica el mismo lematizador realizado previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f71a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lematizador_propio(text):\n",
    "    # Diccionario con las palabras y sus lemas correspondientes\n",
    "    lemmas = {\n",
    "        r\"\\babandona\\b\": \"abandonar\",\n",
    "        r\"\\babandonado\\b\": \"abandonar\",\n",
    "        r\"\\babandonandolo\\b\": \"abandonar\",\n",
    "        r\"\\babandonar\\b\": \"abandonar\",\n",
    "        r\"\\babandono\\b\": \"abandonar\",\n",
    "        r\"\\babandón\\b\": \"abandonar\",\n",
    "        r\"\\babalanzo\\b\": \"abalanzar\",\n",
    "        r\"\\bzurda\\b\": \"zurdo\",\n",
    "        r\"\\bzurdazo\\b\": \"zurdo\",\n",
    "        r\"\\bzurdito\\b\": \"zurdo\",\n",
    "        r\"\\bzurraba\\b\": \"zurrar\",\n",
    "        r\"\\bzurrartir\\b\": \"zurrar\",\n",
    "        r\"\\bzozobra\\b\": \"zozobrar\"\n",
    "    }\n",
    "    for pattern, lemma in lemmas.items():\n",
    "        text = re.sub(pattern, lemma, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "clean_sentences2 = list(map(Lematizador_propio, clean_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a04e7",
   "metadata": {},
   "source": [
    "Y una vez definido el nuevo lematizador se vuelve a implementar TfidfVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e31620",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(clean_sentences2)\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37147e",
   "metadata": {},
   "source": [
    "Se calcula la distancia de coseno que se guarda en el objeto cosine_sim2 sobre la matriz calculada por TfidfVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim2 = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b657f9",
   "metadata": {},
   "source": [
    "Para aplicar el recomendador usando la matriz calculada por TfidfVectorizer. Para esto se modifica la opción cosine_sim por cosine_sim2 que contiene las distancias coseno calculadas en la matriz TfidfVectorizer. La ordenación fue realizada dentro de la función recomendador. En la línea sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True) se ordenan los puntajes calculados y en la línea sim_scores = sim_scores[1:6] se extraen los primeros 6. El único cuento que coincide en ambos métodos es el cuento \"Gaussian blur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendador(\"La venganza del metegol\", cosine_sim = cosine_sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4932e62",
   "metadata": {},
   "source": [
    "A pesar de que los cuentos recomendados fueron diferentes en su mayoría, los términos más repetidos son muy similares a los obtenidos previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cuentos_rec=df[df['titulo'].isin(recomendador(\"La venganza del metegol\", cosine_sim = cosine_sim2))]\n",
    "\n",
    "text = \" \".join(cuentos_rec['cuento'])\n",
    "text = text_cleaning(text)\n",
    "text=' '.join(text)\n",
    "text = Lematizador_propio(text)\n",
    "\n",
    "wordcloud = WordCloud(width = 1600, height = 800, \n",
    "    background_color = \"white\").generate(text)\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.3. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando el texto vectorizado por `TF-IDFVectorizer` y la correlación como medida de similitud. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados de los puntos anteriores y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilice este espacio para escribir el código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir el procedimiento, análisis, y conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Recomendaciones basadas en temas\n",
    "\n",
    "Usando modelado de temas con LDA, encuentre los temas subyacentes en el blog. Explique como eligió el numero óptimo de temas. Utilizando el tema asignado al cuento 'La venganza del metegol' y la probabilidad de pertenecer a este tema genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para este cuento. Explique el procedimiento que realizó. Compare con los resultados encontrados anteriormente y explique sus similitudes y/o diferencias. (Esto puede tomar mucho tiempo y requerir mucha capacidad computacional, puede aprovechar los recursos de [Google Colab](https://colab.research.google.com/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilice este espacio para escribir el código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir el procedimiento, análisis, y conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Recomendaciones generales\n",
    "\n",
    "De acuerdo con los resultados encontrados, en su opinión ¿qué procedimiento generó las mejores recomendaciones para la entrada elegida? ¿Cómo implementaría una evaluación objetiva de estas recomendaciones? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir su procedimiento)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
